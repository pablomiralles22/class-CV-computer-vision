{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNQ8a0fAbuKTRWRWl0VUVdg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pablomiralles22/class-CV-computer-vision/blob/main/YOLO_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "akFfxiHT7Jua"
      },
      "outputs": [],
      "source": [
        "!pip install transformers torch torchvision matplotlib pillow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import requests\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "from transformers import YolosImageProcessor, YolosForObjectDetection\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "QWdTskB19ery"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
        "image = Image.open(requests.get(url, stream=True).raw)\n",
        "\n",
        "model = YolosForObjectDetection.from_pretrained('hustvl/yolos-tiny')\n",
        "image_processor = YolosImageProcessor.from_pretrained(\"hustvl/yolos-tiny\")\n",
        "\n",
        "inputs = image_processor(images=image, return_tensors=\"pt\")\n",
        "outputs = model(**inputs)\n",
        "\n",
        "# model predicts bounding boxes and corresponding COCO classes\n",
        "logits = outputs.logits\n",
        "bboxes = outputs.pred_boxes\n",
        "\n",
        "# print results\n",
        "target_sizes = torch.tensor([image.size[::-1]])\n",
        "results = image_processor.post_process_object_detection(outputs, threshold=0.9, target_sizes=target_sizes)[0]\n",
        "for score, label, box in zip(results[\"scores\"], results[\"labels\"], results[\"boxes\"]):\n",
        "    box = [round(i, 2) for i in box.tolist()]\n",
        "    print(\n",
        "        f\"Detected {model.config.id2label[label.item()]} with confidence \"\n",
        "        f\"{round(score.item(), 3)} at location {box}\"\n",
        "    )"
      ],
      "metadata": {
        "id": "ESlcJSYW7l8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the image\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.imshow(image)\n",
        "ax = plt.gca()\n",
        "\n",
        "# Add each bounding box and label\n",
        "for score, label, box in zip(results[\"scores\"], results[\"labels\"], results[\"boxes\"]):\n",
        "    xmin, ymin, xmax, ymax = box.tolist()\n",
        "    width, height = xmax - xmin, ymax - ymin\n",
        "    rect = patches.Rectangle(\n",
        "        (xmin, ymin), width, height,\n",
        "        linewidth=2, edgecolor=\"red\", facecolor=\"none\"\n",
        "    )\n",
        "    ax.add_patch(rect)\n",
        "    label_text = f\"{model.config.id2label[label.item()]}: {score.item():.2f}\"\n",
        "    ax.text(xmin, ymin - 5, label_text, color=\"white\",\n",
        "            fontsize=12, bbox=dict(facecolor=\"red\", alpha=0.5))\n",
        "\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-CD-5WPo9W2A"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}